{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>Run Text_Matcher Algorithm</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Troubleshooting: !jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 if you \n",
    "# get a message about the data rate limit\n",
    "\n",
    "\n",
    "# import libraries needed\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# TBD: Some of these libraries are relics of earlier notebooks.\n",
    "# Reactivate any of the following that are needed, delete any that aren't needed.\n",
    "\n",
    "try:\n",
    "   import nltk\n",
    "except:   \n",
    "   !{sys.executable} -m pip install nltk\n",
    "\n",
    "try:\n",
    "   import termcolor\n",
    "except:   \n",
    "   !{sys.executable} -m pip install termcolor\n",
    "\n",
    "from matcher import Text, Matcher\n",
    "\n",
    "\n",
    "try:   \n",
    "   from IPython.display import clear_output\n",
    "except:\n",
    "   !{sys.executable} -m pip install IPython.display \n",
    "   from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "   from matcher import Text, Matcher\n",
    "except:\n",
    "   !{sys.executable} -m pip install matcher\n",
    "   from matcher import Text, Matcher\n",
    "\n",
    "try:\n",
    "    import re\n",
    "except:\n",
    "    !{sys.executable} -m pip install re\n",
    "    import re\n",
    "\n",
    "\n",
    "try:\n",
    "    import json\n",
    "except:\n",
    "    !{sys.executable} -m pip install json\n",
    "    import json\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except:\n",
    "    !{sys.executable} -m pip install ipywidgets\n",
    "    import ipywidgets as widgets\n",
    "\n",
    "#%pip install altair\n",
    "\n",
    "try:\n",
    "    import altair as alt\n",
    "except:\n",
    "    !{sys.executable} -m pip install altair\n",
    "    import altair as alt\n",
    "\n",
    "\n",
    "try:\n",
    "    from pathlib import Path\n",
    "except:\n",
    "    !{sys.executable} -m pip install pathlib\n",
    "    from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except:\n",
    "    !{sys.executable} -m pip install IPython.display\n",
    "    from IPython.display import display\n",
    "\n",
    "#new viz library for single-column heatmap    \n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    !{sys.executable} -m pip install matplotlib.pyplot\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    from tabulate import tabulate \n",
    "except:\n",
    "    !{sys.executable} -m pip install tabulate\n",
    "    from tabulate import tabulate\n",
    "\n",
    "\n",
    "try:\n",
    "    from ipywidgets import Label\n",
    "except:\n",
    "    !{sys.executable} -m pip ipwidgets\n",
    "    from ipywidgets import Label\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "try:\n",
    "    import seaborn as sns \n",
    "except:\n",
    "    !{sys.executable} -m pip install seaborn\n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "#from nltk.corpus import names\n",
    "#from collections import Counter\n",
    "#from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "#plt.rcParams[\"figure.figsize\"] = [16, 6]\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43d9a970c824ee5ad8383fdde77d36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Paste the path below:'), Textarea(value='C:\\\\Users\\\\bdt\\\\Documents\\\\Data', descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ACTION: copy path to data directory \n",
    "#🚨  default in developer stage:  r\"C:\\Users\\bdt\\Documents\\Data\"\n",
    "\n",
    "# Create a text widget for the path input\n",
    "path_data_dir_input = widgets.Textarea(\n",
    "    # 🚨has to be removed \n",
    "    value= r\"C:\\Users\\bdt\\Documents\\Data\",\n",
    "    placeholder=\"Paste the path here\",\n",
    "    description=\"Path:\",\n",
    "    rows=6,\n",
    "    width= 30)\n",
    "# Add the instruction line above the input field\n",
    "path_data_dir_instruction_line = widgets.Label(\"Paste the path below:\")\n",
    "\n",
    "path_data_dir=path_data_dir_input.value\n",
    "path_data_dir2 =Path(path_data_dir)\n",
    "\n",
    "\n",
    "# Create a VBox layout with the path_input widget\n",
    "instruction_data_dir_line= widgets.Label(\"Paste the path below:\")\n",
    "\n",
    "panel_data_dir_layout = widgets.VBox([path_data_dir_input])\n",
    "\n",
    "# Create a button widget for the commit action\n",
    "commit_data_dir_button = widgets.Button(description=\"Confirm\")\n",
    "text_data_dir_label = widgets.Label(value=\"\")\n",
    "commit_data_dir_box= widgets.HBox([commit_data_dir_button, text_data_dir_label])\n",
    "\n",
    "panel_data_dir_layout.children = (instruction_data_dir_line, path_data_dir_input, commit_data_dir_box)\n",
    "\n",
    "# Define the event handler for the commit button\n",
    "# Update the commit_button_clicked function\n",
    "\n",
    "\n",
    "def input_field_changed(change):\n",
    "    new_path = change['new']\n",
    "    new_path = new_path.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "    new_path = new_path.replace(\"'\", \"\")\n",
    "    new_path = new_path.replace('\"', '')\n",
    "    if Path(new_path).exists():\n",
    "        instruction_data_dir_line.value = \"Paste the path below:\"\n",
    "        text_data_dir_label.value = 'This path exists'\n",
    "        commit_data_dir_button.layout.visibility = 'visible'\n",
    "        commit_data_dir_button.description = 'Confirm'\n",
    "    else:\n",
    "        commit_data_dir_button.layout.visibility = 'hidden'\n",
    "        instruction_data_dir_line.value = \"Please try again. Paste the path below\"\n",
    "        text_data_dir_label.value = 'This path does not exist'\n",
    "    \n",
    "    if Path(new_path).exists():\n",
    "        instruction_data_dir_line.value = \"Paste the path below:\"\n",
    "        text_data_dir_label.value = 'This path exists'\n",
    "        commit_data_dir_button.layout.visibility = 'visible'\n",
    "\n",
    "        commit_data_dir_button.description = 'Confirm'\n",
    "    else:\n",
    "        commit_data_dir_button.layout.visibility = 'hidden'\n",
    "        # commit_button.visible = False\n",
    "        instruction_data_dir_line.value = \"Please try again. Paste the path below\"\n",
    "        text_data_dir_label.value = 'This path does not exit' \n",
    "    # Perform actions based on the new value\n",
    "    \n",
    "# Attach the event handler to the value change event of input_field\n",
    "path_data_dir_input.observe(input_field_changed, names='value')\n",
    "\n",
    "def commit_data_dir_button_clicked(button):\n",
    "    global path_data_dir, path_data_dir2\n",
    "    new_path= str( path_data_dir_input.value).replace(\"\\\\\",\"\\\\\\\\\")\n",
    "    new_path = new_path.replace(\"'\", \"\")\n",
    "    new_path = new_path.replace('\"', '')\n",
    "    exists= Path(new_path).exists()\n",
    "    if  exists:\n",
    "        instruction_data_dir_line.value=\"Paste the data root path below:\"\n",
    "        path_data_dir = new_path\n",
    "        path_data_dir2 = Path(new_path)\n",
    "        commit_data_dir_button.description='Confirmed'\n",
    "        text_data_dir_label.value='This path exists'\n",
    "    else:\n",
    "        instruction_data_dir_line.value=\"Please try again. Paste the path below\"\n",
    "        text_data_dir_label.value='This path does not exist'\n",
    "\n",
    "# Attach the event handler to the commit button\n",
    "commit_data_dir_button.on_click(commit_data_dir_button_clicked)\n",
    "# Display the panel\n",
    "display(panel_data_dir_layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an analysis on the basis of the subdir structure, to get list of all the available authors, and all the books that are available\n",
    "# the full bookname is formally built by the publication year and the book title, searated by an underscore \n",
    "# make a class that contains and synchronizes all functionality and structure knowlegde \n",
    "# apply this class to the existing data \n",
    "\n",
    "# make a panel to view and select the authorname and the full book name to work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and apply a panel to view and select the authorname and the full book name to work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION:  paste the data_directory in the inputfield "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class generic_analysis_datastructure:\n",
    "    \n",
    "# This cell defines a class and functions for managing project data\n",
    "\n",
    "# 🗣️ The class and functions need to be rewritten to only check for the existence of the correct folder structure\n",
    "# and give an error message if relevant folders are missing. 🗣️🚨\n",
    "\n",
    "# using pathlib\n",
    "# dataDir is the main directory of all projects of all authors \n",
    "#  \n",
    "\n",
    "\n",
    "def file_exists(full_filename_string):\n",
    "  filename_path = Path(full_filename_string)\n",
    "\n",
    "  if filename_path.exists():        \n",
    "    if filename_path.is_file():\n",
    "      return True\n",
    "    else:\n",
    "      print(f\"{filename_path} exists, but it is not a file.\")\n",
    "      return False    \n",
    "  else:\n",
    "    print(f\"{filename_path} does not exist.\")\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define project dir, short filename, make project data\n",
    "\n",
    "class ProjectData2:\n",
    "  def __init__(self, data_dir, author_name, pub_book_name):\n",
    "   \n",
    "    #dataFDir is string of root dir path\n",
    "\n",
    "    self.pub_book_name=pub_book_name\n",
    "    self.author_name = author_name\n",
    "    self.project_name=f\"{self.author_name}_{self.pub_book_name}\"\n",
    "  \n",
    "    self.data_dir = Path(data_dir)\n",
    "    \n",
    "    # define all the project dirs\n",
    "    self.project_dir= Path(self.data_dir/self.author_name/pub_book_name)\n",
    "    self.source_dir= Path(self.project_dir/'SourceText')\n",
    "    #self.source_dir_path = Path.mkdir(exist_ok=True)\n",
    "    self.corpus_dir=Path(self.project_dir/'TargetCorpus')\n",
    "    #self.corpus_dir.mkdir(exist_ok=True)\n",
    "    self.results_dir=Path(self.project_dir/'Results')\n",
    "    #self.results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "  \n",
    "    #self.scan_project_data()\n",
    "    # check if all the prject dirs exist \n",
    "    self.all_project_dirs_exist()\n",
    "    \n",
    "    \n",
    "  def make_project_dirs(self):\n",
    "    if not self.source_dir.exists():\n",
    "      self.source_dir.mkdir(exist_ok=True)\n",
    "    if not self.corpus_dir.exists():\n",
    "      self.corpus_dir.mkdir(exist_ok=True)\n",
    "    if not self.results_dir.exists():\n",
    "      self.results_dir.mkdir(exist_ok=True)\n",
    "    return     \n",
    "\n",
    "\n",
    "  def all_project_dirs_exist(self):\n",
    "    #preetting the value of the return variable exist to False  \n",
    "    data_dir_exists= self.data_dir.exists()\n",
    "    if not data_dir_exists: \n",
    "      print( f\"The data directory {self.dataDir}  does not exist\")\n",
    "    else:\n",
    "      data_dir_exists = True\n",
    "      results_dir_exists = self.results_dir.exists()\n",
    "      if not results_dir_exists:\n",
    "        print( f\"The results directory {self.results_dir}  does not exist\")\n",
    "      else:\n",
    "        results_dir_exists = True \n",
    "      corpus_dir_exists = self.corpus_dir.exists()\n",
    "      if not corpus_dir_exists:\n",
    "        print( f\"The corpus directory {self.corpus_dir}  does not exist\")\n",
    "      else:\n",
    "        corpus_dir_exists = True  \n",
    "      \n",
    "      source_dir_exists = self.source_dir.exists()\n",
    "      if not source_dir_exists:\n",
    "        print( f\"The source directory {self.source_dir}  does not exist\")\n",
    "      else:  \n",
    "        source_dir_exists = True      \n",
    "    all_dirs_exist = data_dir_exists and source_dir_exists and results_dir_exists and corpus_dir_exists and source_dir_exists\n",
    "    return all_dirs_exist\n",
    "\n",
    "  def read_sourcetextA(self):\n",
    "    self.sourceText_name = str(Path(self.source_dir/f\"{self.project_name}_plaintext.txt\"))\n",
    "    with open(self.sourceText_name) as f: \n",
    "      rawText = f.read()\n",
    "    self.plain_sourcetextA = Text(rawText,self.project_name)\n",
    "    return self.plain_sourcetextA\n",
    "\n",
    "\n",
    "# Load the corpus you want to find results in\n",
    "  def read_corpusA(self):\n",
    "    self.corpusFile_path = Path(self.corpus_dir/f\"{self.project_name}_fulltext.jsonl\")\n",
    "    with open(self.corpusFile_path) as f:\n",
    "      rawProcessedData = f.readlines()\n",
    "    self.data_fulltext_jsonl = [json.loads(line) for line in rawProcessedData]\n",
    "    return self.data_fulltext_jsonl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#def scan_book_projects(data_dir, author_name):\n",
    "#    author_dir = Path(data_dir / author_name)\n",
    "#    book_projects_list = [folder.name for folder in os.scandir(str(author_dir)) if folder.is_dir()]\n",
    "#    return book_projects_list\n",
    "\n",
    "def make_project_name(pub_year,book_title):\n",
    "    project_name= f\"{pub_year}_{book_title}\" \n",
    "    return project_name\n",
    "\n",
    "def make_pub_year(project_name):\n",
    "    pub_year = project_name.split(\"_\")[0]\n",
    "    return pub_year\n",
    "\n",
    "def scan_book_projects(data_dir, author_name):\n",
    "    author_dir = os.path.join(str(data_dir), author_name)\n",
    "    book_projects_list = [folder.name for folder in os.scandir(author_dir) if folder.is_dir()]\n",
    "    return book_projects_list\n",
    "\n",
    "def make_book_title(project_name):\n",
    "    book_title = project_name.split(\"_\")[1]\n",
    "    return book_title    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1925_Dalloway']\n"
     ]
    }
   ],
   "source": [
    "author_name='Woolf'\n",
    "\n",
    "print(scan_book_projects(path_data_dir, author_name))\n",
    "\n",
    "\n",
    "\n",
    "#pub_booktitle_name=\n",
    "\n",
    "#project=ProjectData2(data_dir, author_name, pub_booktitle_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProjectsData:\n",
    "    def scan_Subdirs(self, data_Dir):\n",
    "        #dataDir is a pathlib Path object\n",
    "        authors_list = [folder.name for folder in os.scandir(str(data_Dir)) if folder.is_dir()]\n",
    "        self.authors_list = authors_list\n",
    "        return authors_list\n",
    "\n",
    "    def __init__(self, data_Dir):\n",
    "        self.data_Dir = data_Dir\n",
    "        self.authors_list = self.scan_Subdirs(self.data_Dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eliot', 'Joyce', 'Woolf']\n"
     ]
    }
   ],
   "source": [
    "all_projects = ProjectsData(path_data_dir2)\n",
    "\n",
    "\n",
    "print(all_projects.authors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076476ff1d8141d4be19a310b8d168a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Chose your project, and press Confirm button:'), Dropdown(description='Authors:', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus directory C:\\Users\\bdt\\Documents\\Data\\Joyce\\1922_Ulysses\\TargetCorpus  does not exist\n",
      "C:\\Users\\bdt\\Documents\\Data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ACTION: \n",
    "#🚨  \n",
    "\n",
    "\n",
    "instruction_line = widgets.Label(\"Chose your project, and press Confirm button:\")\n",
    "\n",
    "# Create a dropdown widget\n",
    "authors_dropdown = widgets.Dropdown(\n",
    "    options=all_projects.authors_list,\n",
    "    description='Authors:'\n",
    "    )\n",
    "\n",
    "author_name= authors_dropdown.value\n",
    "\n",
    "books_dropdown = widgets.Dropdown(\n",
    "    options=scan_book_projects(path_data_dir, author_name),\n",
    "    description='Books:'\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a VBox layout with the path_input widget\n",
    "# panel_layout = widgets.VBox([authors_dropdown, books_dropdown  ])\n",
    "\n",
    "# Create a button widget for the commit action\n",
    "commit_button = widgets.Button(description=\"Confirm\")\n",
    "text_label=widgets.Label(value=\"\")\n",
    "commit_box= widgets.HBox([commit_button, text_label])\n",
    "panel_layout=widgets.VBox()\n",
    "panel_layout.children = (instruction_line,authors_dropdown, books_dropdown, commit_box)\n",
    "\n",
    "def author_name_changed(change):\n",
    "    global author_name, books_dropdown\n",
    "    \n",
    "    author_name = change['new']\n",
    "    books_dropdown.options = scan_book_projects(path_data_dir, author_name)\n",
    "    books_dropdown.value = books_dropdown.options[0]  # Select the first book by default\n",
    "    commit_button.description='Confirm'\n",
    "\n",
    "# Attach the event handler to the value change event of authors_dropdown\n",
    "authors_dropdown.observe(author_name_changed, names='value')\n",
    "\n",
    "\n",
    "def input_author_field_changed(change):\n",
    "    new_path = change['new']\n",
    "    new_path = new_path.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "    new_path = new_path.replace(\"'\", \"\")\n",
    "    new_path = new_path.replace('\"', '')\n",
    "    if Path(new_path).exists():\n",
    "        instruction_data_dir_line.value = \"Paste the path below:\"\n",
    "        text_data_dir_label.value = 'This path exists'\n",
    "        commit_data_dir_button.layout.visibility = 'visible'\n",
    "        commit_data_dir_button.description = 'Confirm'\n",
    "    else:\n",
    "        commit_data_dir_button.layout.visibility = 'hidden'\n",
    "        instruction_data_dir_line.value = \"Please try again. Paste the path below\"\n",
    "        text_data_dir_label.value = 'This path does not exist'\n",
    "    \n",
    "    if Path(new_path).exists():\n",
    "        instruction_data_dir_line.value = \"Paste the path below:\"\n",
    "        text_data_dir_label.value = 'This path exists'\n",
    "        commit_data_dir_button.layout.visibility = 'visible'\n",
    "\n",
    "        commit_data_dir_button.description = 'Confirm'\n",
    "    else:\n",
    "        commit_data_dir_button.layout.visibility = 'hidden'\n",
    "        # commit_button.visible = False\n",
    "        instruction_data_dir_line.value = \"Please try again. Paste the path below\"\n",
    "        text_data_dir_label.value = 'This path does not exit' \n",
    "    # Perform actions based on the new value\n",
    "    \n",
    "# Attach the event handler to the value change event of dropbox.value\n",
    "authors_dropdown.observe(input_author_field_changed, names='value')\n",
    "\n",
    "def commit_button_clicked(button):\n",
    "    global author_name, pub_title_name,book_proj\n",
    "    instruction_line.value=\"Paste the path below:\"\n",
    "    author_name= authors_dropdown.value\n",
    "    pub_title_name= books_dropdown.value\n",
    "    book_proj=ProjectData2(path_data_dir, author_name, pub_title_name)   \n",
    "\n",
    "    print( book_proj.data_dir)\n",
    "    commit_button.description='Confirmed'\n",
    "\n",
    "    #text_label.value='This path exists'\n",
    "    \n",
    "# Attach the event handler to the commit button\n",
    "commit_button.on_click(commit_button_clicked)\n",
    "# Display the panel\n",
    "display(panel_layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines a class and functions for managing project data\n",
    "\n",
    "# 🗣️ The class and functions need to be rewritten to only check for the existence of the correct folder structure\n",
    "# and give an error message if relevant folders are missing. 🗣️🚨\n",
    "\n",
    "# using pathlib\n",
    "# dataDir is the main directory of all projects of all authors \n",
    "#  \n",
    "\n",
    "\n",
    "def file_exists(full_filename_string):\n",
    "  filename_path = Path(full_filename_string)\n",
    "\n",
    "  if filename_path.exists():        \n",
    "    if filename_path.is_file():\n",
    "      return True\n",
    "    else:\n",
    "      print(f\"{filename_path} exists, but it is not a file.\")\n",
    "      return False    \n",
    "  else:\n",
    "    print(f\"{filename_path} does not exist.\")\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# define project dir, short filename, make project data\n",
    "\n",
    "class ProjectData:\n",
    "  def __init__(self,the_filename, the_dataDir):\n",
    "    #the_filename is full file path in the current OS\n",
    "    #dataFDir is string of root dir path\n",
    "    self.filename = the_filename\n",
    "    self.dataDir = Path(the_dataDir)\n",
    "    #self.dataDir.mkdir(exist_ok=True)\n",
    "    self.project_name = self.filename.split('.')[0] \n",
    "   \n",
    "    self.make_project_data()\n",
    "    self.project_dir = self.dataDir/self.name_author/self.project_name   \n",
    "    #self.project_dir.mkdir(exist_ok=True) \n",
    "    \n",
    "    # these should theoretically already be created in other NB \n",
    "    # But  working on an other laptop with other OS it can be handy \n",
    "    # to have these directories  written in the current OS fashion  \n",
    "    #self.proj_dir= Path(self.dataDir/self.name_author/self.project_name)\n",
    "    \n",
    "    self.source_dir= Path(self.project_dir/'SourceText')\n",
    "    #self.source_dir_path = Path.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "    self.corpus_dir=Path(self.project_dir/'TargetCorpus')\n",
    "    #self.corpus_dir.mkdir(exist_ok=True)\n",
    "    self.results_dir=Path(self.project_dir/'Results')\n",
    "    #self.results_dir.mkdir(exist_ok=True)\n",
    "    self.path=self.results_dir/self.filename \n",
    "\n",
    "\n",
    "    # Create a Path object\n",
    "    # directory_path= Path(dir_name_string)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    # if not( directory_path.exists() and directory_path.is_dir()):\n",
    "    #   print(f\"{dir_name_string} does not exist as a directory.\")\n",
    "\n",
    "    \n",
    "  def make_project_data(self):\n",
    "    #Split the_filename into parts based on the underscore character\n",
    "    parts = self.filename.split('_')\n",
    "    # The first part is the author's name\n",
    "    self.name_author = parts[0]\n",
    "    # The second part is the publication year\n",
    "    self.publication_year = parts[1]\n",
    "    # The third part is the book's name\n",
    "    self.text_title = parts[2]   \n",
    "    self.suffix1 = parts[3] \n",
    "    # The fourth part contains the suffix and the extension\n",
    "    suffix_and_extension = parts[4]\n",
    "\n",
    "    # Split the fourth part into the suffix and the extension based on the period character\n",
    "    suffix_parts = suffix_and_extension.split('.')    \n",
    "    # The first part is the hyperparSuffix\n",
    "    self.hyperparSuffix = suffix_parts[0]\n",
    "    # The second part is the extension\n",
    "    self.extension = suffix_parts[1]\n",
    "    self.project_name=f\"{self.name_author}_{self.publication_year}_{self.text_title}\"\n",
    "\n",
    "    #this method checks if all of the project directorie exist. \n",
    "    # It returns true if so, and False if not\n",
    "\n",
    "  def all_project_dirs_exist(self):\n",
    "    #preetting the value of the return variable exist to False  \n",
    "    data_dir_exists= self.dataDir.exists()\n",
    "    if not data_dir_exists: \n",
    "      print( f\"The data directory {self.dataDir}  does not exist\")\n",
    "    else:\n",
    "      data_dir_exists = True\n",
    "      results_dir_exists = self.results_dir.exists()\n",
    "      if not results_dir_exists:\n",
    "        print( f\"The results directory {self.results_dir}  does not exist\")\n",
    "      else:\n",
    "        results_dir_exists = True \n",
    "      corpus_dir_exists = self.corpus_dir.exists()\n",
    "      if not corpus_dir_exists:\n",
    "        print( f\"The corpus directory {self.corpus_dir}  does not exist\")\n",
    "      else:\n",
    "        corpus_dir_exists = True  \n",
    "      \n",
    "      source_dir_exists = self.source_dir.exists()\n",
    "      if not source_dir_exists:\n",
    "        print( f\"The source directory {self.source_dir}  does not exist\")\n",
    "      else:  \n",
    "        source_dir_exists = True \n",
    "     \n",
    "    all_dirs_exist = data_dir_exists and source_dir_exists and results_dir_exists and corpus_dir_exists and source_dir_exists\n",
    "\n",
    "    return all_dirs_exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eliot', 'Joyce', 'Woolf']\n"
     ]
    }
   ],
   "source": [
    "all_projects = ProjectsData(path_data_dir)\n",
    "print(all_projects.authors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: copy path to corpus data JSONL file here (filename should end \"_fulltext.jsonl\")\n",
    "\n",
    "# startData = \"/Users/milan/Library/CloudStorage/GoogleDrive-mtt2126@columbia.edu/My Drive/iAnnotate/MIT/Quotable Content/Data/Dickens/1853_BleakHouse/TargetCorpus/Dickens_1853_BleakHouse_fulltext.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix to be appended to results: _t2-c3-n2-m3-nostops\n"
     ]
    }
   ],
   "source": [
    "# Specify hyperparameters for matcher algorithm (adjust if desired)\n",
    "\n",
    "thresh = 2\n",
    "cut = 3\n",
    "ngram = 2\n",
    "mindist = 3\n",
    "nostops = True\n",
    "\n",
    "hyperparSuffix = f\"_t{thresh}-c{cut}-n{ngram}-m{mindist}-{'nostops' if nostops else 'stops'}\"\n",
    "print(f\"Suffix to be appended to results: {hyperparSuffix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ocationsInA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mocationsInA\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ocationsInA' is not defined"
     ]
    }
   ],
   "source": [
    "occationsinA=fd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text you want to find quotations from.\n",
    "\n",
    "sourceText = f\"{book_proj.source_dir}/{book_proj.project_name}_plaintext.txt\"\n",
    "\n",
    "with open(sourceText, encoding='utf-8') as f: \n",
    "    rawText = f.read()\n",
    "\n",
    "# Load the corpus you want to find results in\n",
    "\n",
    "#corpusFile = f\"{corpusDir}/{self.projectName}_fulltext.jsonl\"\n",
    "\n",
    "#with open(corpusFile) as f:\n",
    "#    rawProcessedData = f.readlines()\n",
    "#data = [json.loads(line) for line in rawProcessedData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m matchesTally \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, article \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdata\u001b[49m): \n\u001b[0;32m      4\u001b[0m     clear_output()\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m matches made so far. Now matching article \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (matchesTally, i, \u001b[38;5;28mlen\u001b[39m(data)), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "matchesTally = 0\n",
    "\n",
    "for i, article in enumerate(data): \n",
    "    clear_output()\n",
    "    print('\\r', '%s matches made so far. Now matching article %s of %s' % (matchesTally, i, len(data)), end='')\n",
    "    if 'numMatches' not in article: \n",
    "        articleText = Text(article['fullText'], article['id'], removeStopwords=nostops)\n",
    "        article['numMatches'], article['Locations in A'], article['Locations in B'] = \\\n",
    "        Matcher(tx, articleText, \\\n",
    "                threshold=thresh, cutoff=cut, ngramSize=ngram, \\\n",
    "                removeStopwords=nostops, minDistance=mindist).match()\n",
    "        matchesTally = matchesTally + article['numMatches']\n",
    "        article['fullText'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to pandas dataframe\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop corpus full text from dataset\n",
    "\n",
    "df = df.drop(['fullText'], axis=1)\n",
    "\n",
    "# Extract year from date published\n",
    "\n",
    "df2 = df[\"datePublished\"].str.split(pat=\"-\", n=1, expand=True).rename({0: \"Year\"}, axis=\"columns\")\n",
    "df = pd.concat([df, df2[\"Year\"]], axis=1)\n",
    "df = df.astype({'Year': 'int64'})\n",
    "\n",
    "# Derive decade from year\n",
    "\n",
    "df['Decade'] = df['Year'] - (df['Year'] % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns to be more user-friendly\n",
    "\n",
    "colToMove = df.pop(\"Year\")\n",
    "df.insert(2, \"Year\", colToMove)\n",
    "\n",
    "colToMove = df.pop(\"Decade\")\n",
    "df.insert(3, \"Decade\", colToMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSONL file for analysis and visualization\n",
    "\n",
    "df.to_json(path_or_buf=f\"{resultsDir}/{projectName}_results{hyperparSuffix}.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: reload results file (if resuming later)\n",
    "\n",
    "#resultsData = f\"{resultsDir}/Woolf_1925_Dalloway_results_t3-c3-n2-m5-nostops.jsonl\"\n",
    "#df = pd.read_json(resultsData, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many items include at least 1 match\n",
    "\n",
    "len(df.loc[df[\"numMatches\"] >=1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many matches in total\n",
    "\n",
    "pd.DataFrame.sum(df[\"numMatches\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>Year</th>\n",
       "      <th>Decade</th>\n",
       "      <th>docSubType</th>\n",
       "      <th>docType</th>\n",
       "      <th>doi</th>\n",
       "      <th>id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>isPartOf</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>volumeNumber</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>numMatches</th>\n",
       "      <th>Locations in A</th>\n",
       "      <th>Locations in B</th>\n",
       "      <th>abstract</th>\n",
       "      <th>placeOfPublication</th>\n",
       "      <th>subTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [creator, datePublished, Year, Decade, docSubType, docType, doi, id, identifier, isPartOf, issueNumber, keyphrase, language, outputFormat, pageCount, pageEnd, pageStart, pagination, provider, publicationYear, publisher, sourceCategory, tdmCategory, title, url, volumeNumber, wordCount, numMatches, Locations in A, Locations in B, abstract, placeOfPublication, subTitle]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 33 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that matcher ran on all lines in the dataset - result should be 0\n",
    "\n",
    "df.loc[pd.isnull(df['Locations in A'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datePublished</th>\n",
       "      <th>docSubType</th>\n",
       "      <th>Year</th>\n",
       "      <th>Decade</th>\n",
       "      <th>docType</th>\n",
       "      <th>doi</th>\n",
       "      <th>id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>isPartOf</th>\n",
       "      <th>issueNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>url</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>numMatches</th>\n",
       "      <th>Locations in A</th>\n",
       "      <th>Locations in B</th>\n",
       "      <th>creator</th>\n",
       "      <th>volumeNumber</th>\n",
       "      <th>abstract</th>\n",
       "      <th>placeOfPublication</th>\n",
       "      <th>subTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>misc</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020</td>\n",
       "      <td>article</td>\n",
       "      <td>10.2307/48660064</td>\n",
       "      <td>http://www.jstor.org/stable/48660064</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.2307/48660064'},...</td>\n",
       "      <td>James Joyce Broadsheet</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/48660064</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1978-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1978</td>\n",
       "      <td>1970</td>\n",
       "      <td>document</td>\n",
       "      <td>10.2307/26281985</td>\n",
       "      <td>http://www.jstor.org/stable/26281985</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.2307/26281985'},...</td>\n",
       "      <td>Modern Fiction Studies</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/26281985</td>\n",
       "      <td>5634</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[T. O. Beachcroft]</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-10-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>2002</td>\n",
       "      <td>2000</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.jstor.org/stable/3831651</td>\n",
       "      <td>[{'name': 'issn', 'value': '0022281X'}, {'name...</td>\n",
       "      <td>Journal of Modern Literature</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/3831651</td>\n",
       "      <td>6286</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mauro Piccinini]</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>book-review</td>\n",
       "      <td>1999</td>\n",
       "      <td>1990</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.jstor.org/stable/517434</td>\n",
       "      <td>[{'name': 'issn', 'value': '00346551'}, {'name...</td>\n",
       "      <td>The Review of English Studies</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/517434</td>\n",
       "      <td>789</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Katherine Mullin]</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2010</td>\n",
       "      <td>document</td>\n",
       "      <td>10.2307/26885292</td>\n",
       "      <td>http://www.jstor.org/stable/26885292</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.2307/26885292'},...</td>\n",
       "      <td>James Joyce Literary Supplement</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/26885292</td>\n",
       "      <td>3575</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Michael Patrick Gillespie, Chrissie Van Mierlo]</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19707</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.jstor.org/stable/26924868</td>\n",
       "      <td>[{'name': 'issn', 'value': '11108673'}, {'name...</td>\n",
       "      <td>Alif: Journal of Comparative Poetics</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/26924868</td>\n",
       "      <td>8903</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Levi Thompson, ليڤاي تومسون]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This article argues for a new direction in com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mapping East-East Exchanges between Arabic and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19708</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>book-review</td>\n",
       "      <td>2013</td>\n",
       "      <td>2010</td>\n",
       "      <td>article</td>\n",
       "      <td>10.2307/26376124</td>\n",
       "      <td>http://www.jstor.org/stable/26376124</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.2307/26376124'},...</td>\n",
       "      <td>PAJ: A Journal of Performance and Art</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/26376124</td>\n",
       "      <td>2369</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Jason Fitzgerald, David Greenspan, David Gree...</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19709</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>2007</td>\n",
       "      <td>2000</td>\n",
       "      <td>article</td>\n",
       "      <td>10.2307/25571016</td>\n",
       "      <td>http://www.jstor.org/stable/25571016</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.2307/25571016'},...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/25571016</td>\n",
       "      <td>1670</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Sean Latham]</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19710</th>\n",
       "      <td>1957-02-01</td>\n",
       "      <td>research-article</td>\n",
       "      <td>1957</td>\n",
       "      <td>1950</td>\n",
       "      <td>article</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.jstor.org/stable/372469</td>\n",
       "      <td>[{'name': 'issn', 'value': '00100994'}, {'name...</td>\n",
       "      <td>College English</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/372469</td>\n",
       "      <td>4056</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Eugene M. Waith]</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19711</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>2010</td>\n",
       "      <td>document</td>\n",
       "      <td>10.2307/26450569</td>\n",
       "      <td>http://www.jstor.org/stable/26450569</td>\n",
       "      <td>[{'name': 'doi', 'value': '10.2307/26450569'},...</td>\n",
       "      <td>James Joyce Broadsheet</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.jstor.org/stable/26450569</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[R.B.]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14861 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datePublished        docSubType  Year  Decade   docType  \\\n",
       "0        2021-06-01              misc  2021    2020   article   \n",
       "1        1978-10-01               NaN  1978    1970  document   \n",
       "2        2002-10-01  research-article  2002    2000   article   \n",
       "4        1999-11-01       book-review  1999    1990   article   \n",
       "5        2019-04-01               NaN  2019    2010  document   \n",
       "...             ...               ...   ...     ...       ...   \n",
       "19707    2020-01-01  research-article  2020    2020   article   \n",
       "19708    2013-01-01       book-review  2013    2010   article   \n",
       "19709    2007-01-01  research-article  2007    2000   article   \n",
       "19710    1957-02-01  research-article  1957    1950   article   \n",
       "19711    2016-02-01               NaN  2016    2010  document   \n",
       "\n",
       "                    doi                                    id  \\\n",
       "0      10.2307/48660064  http://www.jstor.org/stable/48660064   \n",
       "1      10.2307/26281985  http://www.jstor.org/stable/26281985   \n",
       "2                   NaN   http://www.jstor.org/stable/3831651   \n",
       "4                   NaN    http://www.jstor.org/stable/517434   \n",
       "5      10.2307/26885292  http://www.jstor.org/stable/26885292   \n",
       "...                 ...                                   ...   \n",
       "19707               NaN  http://www.jstor.org/stable/26924868   \n",
       "19708  10.2307/26376124  http://www.jstor.org/stable/26376124   \n",
       "19709  10.2307/25571016  http://www.jstor.org/stable/25571016   \n",
       "19710               NaN    http://www.jstor.org/stable/372469   \n",
       "19711  10.2307/26450569  http://www.jstor.org/stable/26450569   \n",
       "\n",
       "                                              identifier  \\\n",
       "0      [{'name': 'doi', 'value': '10.2307/48660064'},...   \n",
       "1      [{'name': 'doi', 'value': '10.2307/26281985'},...   \n",
       "2      [{'name': 'issn', 'value': '0022281X'}, {'name...   \n",
       "4      [{'name': 'issn', 'value': '00346551'}, {'name...   \n",
       "5      [{'name': 'doi', 'value': '10.2307/26885292'},...   \n",
       "...                                                  ...   \n",
       "19707  [{'name': 'issn', 'value': '11108673'}, {'name...   \n",
       "19708  [{'name': 'doi', 'value': '10.2307/26376124'},...   \n",
       "19709  [{'name': 'doi', 'value': '10.2307/25571016'},...   \n",
       "19710  [{'name': 'issn', 'value': '00100994'}, {'name...   \n",
       "19711  [{'name': 'doi', 'value': '10.2307/26450569'},...   \n",
       "\n",
       "                                    isPartOf issueNumber  ...  \\\n",
       "0                     James Joyce Broadsheet         119  ...   \n",
       "1                     Modern Fiction Studies           3  ...   \n",
       "2               Journal of Modern Literature           1  ...   \n",
       "4              The Review of English Studies         200  ...   \n",
       "5            James Joyce Literary Supplement           1  ...   \n",
       "...                                      ...         ...  ...   \n",
       "19707   Alif: Journal of Comparative Poetics          40  ...   \n",
       "19708  PAJ: A Journal of Performance and Art           1  ...   \n",
       "19709                                    NaN           2  ...   \n",
       "19710                        College English           5  ...   \n",
       "19711                 James Joyce Broadsheet         103  ...   \n",
       "\n",
       "                                        url wordCount numMatches  \\\n",
       "0      http://www.jstor.org/stable/48660064      1966          0   \n",
       "1      http://www.jstor.org/stable/26281985      5634          0   \n",
       "2       http://www.jstor.org/stable/3831651      6286          0   \n",
       "4        http://www.jstor.org/stable/517434       789          0   \n",
       "5      http://www.jstor.org/stable/26885292      3575          0   \n",
       "...                                     ...       ...        ...   \n",
       "19707  http://www.jstor.org/stable/26924868      8903          0   \n",
       "19708  http://www.jstor.org/stable/26376124      2369          0   \n",
       "19709  http://www.jstor.org/stable/25571016      1670          0   \n",
       "19710    http://www.jstor.org/stable/372469      4056          0   \n",
       "19711  http://www.jstor.org/stable/26450569       913          0   \n",
       "\n",
       "       Locations in A Locations in B  \\\n",
       "0                  []             []   \n",
       "1                  []             []   \n",
       "2                  []             []   \n",
       "4                  []             []   \n",
       "5                  []             []   \n",
       "...               ...            ...   \n",
       "19707              []             []   \n",
       "19708              []             []   \n",
       "19709              []             []   \n",
       "19710              []             []   \n",
       "19711              []             []   \n",
       "\n",
       "                                                 creator volumeNumber  \\\n",
       "0                                                    NaN          NaN   \n",
       "1                                     [T. O. Beachcroft]           24   \n",
       "2                                      [Mauro Piccinini]           26   \n",
       "4                                     [Katherine Mullin]           50   \n",
       "5       [Michael Patrick Gillespie, Chrissie Van Mierlo]           33   \n",
       "...                                                  ...          ...   \n",
       "19707                      [Levi Thompson, ليڤاي تومسون]          NaN   \n",
       "19708  [Jason Fitzgerald, David Greenspan, David Gree...           35   \n",
       "19709                                      [Sean Latham]           44   \n",
       "19710                                  [Eugene M. Waith]           18   \n",
       "19711                                             [R.B.]          NaN   \n",
       "\n",
       "                                                abstract  placeOfPublication  \\\n",
       "0                                                    NaN                 NaN   \n",
       "1                                                    NaN                 NaN   \n",
       "2                                                    NaN                 NaN   \n",
       "4                                                    NaN                 NaN   \n",
       "5                                                    NaN                 NaN   \n",
       "...                                                  ...                 ...   \n",
       "19707  This article argues for a new direction in com...                 NaN   \n",
       "19708                                                NaN                 NaN   \n",
       "19709                                                NaN                 NaN   \n",
       "19710                                                NaN                 NaN   \n",
       "19711                                                NaN                 NaN   \n",
       "\n",
       "                                                subTitle  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "4                                                    NaN  \n",
       "5                                                    NaN  \n",
       "...                                                  ...  \n",
       "19707  Mapping East-East Exchanges between Arabic and...  \n",
       "19708                                                NaN  \n",
       "19709                                                NaN  \n",
       "19710                                                NaN  \n",
       "19711                                                NaN  \n",
       "\n",
       "[14861 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check some random items without matches to check for false negatives - easiest to refer to PDF\n",
    "\n",
    "df.loc[df[\"numMatches\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
