{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1129c57",
   "metadata": {},
   "source": [
    "# Retroactively add quoted passages and context chunks to existing results\n",
    "\n",
    "This Notebook is a temporary one to retroactively add:\n",
    "- quoted passages in A\n",
    "- quoted passages in B\n",
    "- context chunks left and right of quoted passage in B\n",
    "\n",
    "... to any results JSONL file that was generated without these data.\n",
    "\n",
    "Once all JSONL results files have had this added, this Notebook will become unnecessary and can be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca60b1",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a144bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from matcher import Text, Matcher\n",
    "from IPython.display import clear_output\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab24f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: copy path to results JSONL file here (filename should end \"_results_[hyperparameters].jsonl\")\n",
    "\n",
    "startData = \"/Users/milan/Library/CloudStorage/GoogleDrive-mtt2126@columbia.edu/My Drive/iAnnotate/MIT/Quotable Content/Data/Proust/1922_SwannsMoncrieff/Results/Proust_1922_SwannsMoncrieff_results_t2-c3-n2-m3-nostops.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9585fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer naming variables from path\n",
    "\n",
    "textTitle = startData.rsplit(\"_\", 4)[-3]\n",
    "publicationYear = startData.rsplit(\"_\", 4)[-4]\n",
    "authorSurname = startData.rsplit(\"_\", 4)[-5]\n",
    "authorSurname = authorSurname.rsplit(\"/\", 1)[-1]\n",
    "hyperparSuffix = startData.rsplit(\"_\", 4)[-1]\n",
    "hyperparSuffix = f\"_{hyperparSuffix[:-6]}\"\n",
    "dataDir = startData.rsplit(\"/\", 4)[0]\n",
    "\n",
    "print(f\"Author surname: {authorSurname}\\nPublication year: {publicationYear}\\nText title: {textTitle}\\nHyperparameters suffix: {hyperparSuffix}\\nData directory:{dataDir}\")\n",
    "\n",
    "projectName = f\"{authorSurname}_{publicationYear}_{textTitle}\"\n",
    "sourceDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/SourceText\"\n",
    "corpusDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/TargetCorpus\"\n",
    "resultsDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the source text in which you detected quotations\n",
    "\n",
    "sourceTextPath = f\"{sourceDir}/{projectName}_plaintext.txt\"\n",
    "with open(sourceTextPath) as f: \n",
    "    rawText = f.read()\n",
    "\n",
    "sourceText = Text(rawText, projectName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the JSONL file with the full text of JSTOR articles\n",
    "\n",
    "corpusDF = pd.read_json(f\"{corpusDir}/{projectName}_fulltext.jsonl\", lines=True)\n",
    "print(f\"Loaded {len(corpusDF)} full-text items\")\n",
    "\n",
    "# Create new dataframe with just full text and id\n",
    "fulltextDF = corpusDF[[\"fullText\",\"id\"]]\n",
    "del corpusDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the JSONL file with the results of text matcher\n",
    "\n",
    "resultsDF = pd.read_json(f\"{startData}\", lines=True)\n",
    "print(f\"Loaded {len(resultsDF)} results from text-matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b13f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge full text column with results dataset\n",
    "\n",
    "df = pd.merge(fulltextDF, resultsDF, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ca4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory from initial separate dataframes\n",
    "\n",
    "del fulltextDF\n",
    "del resultsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42934036",
   "metadata": {},
   "source": [
    "# Generate data on quoted passages and context chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b452a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: specify size of context chunks in characters\n",
    "\n",
    "chunkSizeLeft = 250\n",
    "chunkSizeRight = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each match, this cell extracts the quoted passage in the source text, the quoted passage in the corpus\n",
    "# and context chunks left and right of the quoted passage in the corpus\n",
    "\n",
    "# Create empty columns\n",
    "df = df.assign(quotedPassageinA = \"\", quotedPassageinB = \"\", contextChunkLeft = \"\", contextChunkRight = \"\")\n",
    "\n",
    "# Loop over each item in the corpus\n",
    "for item in range(len(df)):\n",
    "    \n",
    "    clear_output()\n",
    "    print(f\"Now extracting quotations and context chunks for item {item + 1} of {len(df)}\")\n",
    "\n",
    "    # Start with empty lists for quotated passages and context chunks\n",
    "    allPassagesInA = []\n",
    "    allPassagesInB = []\n",
    "    allChunksLeft = []\n",
    "    allChunksRight = []\n",
    "    \n",
    "    # Process the given corpus item text to be in matcher format\n",
    "    corpusItemText = Text(df['fullText'].iloc[item], projectName)\n",
    "    \n",
    "    # Loop over each match for the given item\n",
    "    for match in range(len(df[\"Locations in B\"].iloc[item])):\n",
    "        \n",
    "        # Specify start and end indexes in source text\n",
    "        locInA = df[\"Locations in A\"].iloc[item][match]\n",
    "        \n",
    "        # Append quoted passage in A to list of all quoted passages for item\n",
    "        allPassagesInA.append(sourceText.text[locInA[0]:locInA[1]])\n",
    "\n",
    "        # Specify start and end indexes in item from corpus\n",
    "        locInB = df[\"Locations in B\"].iloc[item][match]\n",
    "        \n",
    "        # Append quoted passage in B to list of all quoted passages for item\n",
    "        allPassagesInB.append(corpusItemText.text[locInB[0]:locInB[1]])\n",
    "        \n",
    "        # Append left context chunk to list of all left context chunks for item\n",
    "        allChunksLeft.append(corpusItemText.text[locInB[0] - chunkSizeLeft:locInB[0]])\n",
    "        \n",
    "        # Append right context chunk to list of all right context chunks for item\n",
    "        allChunksRight.append(corpusItemText.text[locInB[1]:locInB[1] + chunkSizeRight])\n",
    "        \n",
    "    # Assign lists of quoted passages and context chunks to relevant column and row of dataframe\n",
    "    df[\"quotedPassageinA\"].iat[item] = allPassagesInA\n",
    "    df[\"quotedPassageinB\"].iat[item] = allPassagesInB\n",
    "    df[\"contextChunkLeft\"].iat[item] = allChunksLeft\n",
    "    df[\"contextChunkRight\"].iat[item] = allChunksRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91863555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop corpus full text from dataset (important for copyright protection and to reduce file size)\n",
    "\n",
    "df = df.drop(['fullText'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecefa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pandas dataframe as JSONL file\n",
    "\n",
    "df.to_json(path_or_buf=f\"{resultsDir}/{projectName}_results{hyperparSuffix}.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9485dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
