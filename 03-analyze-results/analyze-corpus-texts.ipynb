{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47c3c3a",
   "metadata": {},
   "source": [
    "# Getting \"context chunks\"\n",
    "\n",
    "For a specified character index range, let's retrieve some of the context left and right of that range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503f1ef",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b9f8a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from text_matcher.matcher import Text, Matcher\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "75fc130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: copy path to results JSONL file here (filename should end \"_results_[hyperparameters].jsonl\")\n",
    "\n",
    "startData = \"/Users/milan/Library/CloudStorage/GoogleDrive-mtt2126@columbia.edu/My Drive/iAnnotate/MIT/Quotable Content/Data/Woolf/1925_Dalloway/Results/Woolf_1925_Dalloway_results_t2-c3-n2-m3-nostops.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f9339de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author surname: Woolf\n",
      "Publication year: 1925\n",
      "Text title: Dalloway\n",
      "Hyperparameters suffix: _t2-c3-n2-m3-nostops\n",
      "Data directory:/Users/milan/Library/CloudStorage/GoogleDrive-mtt2126@columbia.edu/My Drive/iAnnotate/MIT/Quotable Content/Data\n"
     ]
    }
   ],
   "source": [
    "# Infer naming variables from path\n",
    "\n",
    "textTitle = startData.rsplit(\"_\", 4)[-3]\n",
    "publicationYear = startData.rsplit(\"_\", 4)[-4]\n",
    "authorSurname = startData.rsplit(\"_\", 4)[-5]\n",
    "authorSurname = authorSurname.rsplit(\"/\", 1)[-1]\n",
    "hyperparSuffix = startData.rsplit(\"_\", 4)[-1]\n",
    "hyperparSuffix = f\"_{hyperparSuffix[:-6]}\"\n",
    "dataDir = startData.rsplit(\"/\", 4)[0]\n",
    "\n",
    "print(f\"Author surname: {authorSurname}\\nPublication year: {publicationYear}\\nText title: {textTitle}\\nHyperparameters suffix: {hyperparSuffix}\\nData directory:{dataDir}\")\n",
    "\n",
    "projectName = f\"{authorSurname}_{publicationYear}_{textTitle}\"\n",
    "sourceDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/SourceText\"\n",
    "corpusDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/TargetCorpus\"\n",
    "resultsDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "27267da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source text\n",
    "\n",
    "with open(f\"{sourceDir}/{projectName}_plaintext.txt\") as f: \n",
    "    rawText = f.read()\n",
    "\n",
    "mm = Text(rawText, 'Middlemarch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "738d1f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2495 full-text items\n"
     ]
    }
   ],
   "source": [
    "# Load in the JSONL file with the full text of JSTOR articles\n",
    "\n",
    "corpusDF = pd.read_json(f\"{corpusDir}/{projectName}_fulltext.jsonl\", lines=True)\n",
    "print(f\"Loaded {len(corpusDF)} full-text items\")\n",
    "\n",
    "# Create new dataframe with just full text and id\n",
    "fulltextDF = corpusDF[[\"fullText\",\"id\"]]\n",
    "del corpusDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88d826f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2495 results from text-matcher\n"
     ]
    }
   ],
   "source": [
    "# Load in the JSONL file with the results of text matcher\n",
    "\n",
    "resultsDF = pd.read_json(f\"{startData}\", lines=True)\n",
    "print(f\"Loaded {len(resultsDF)} results from text-matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d0826a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(fulltextDF, resultsDF, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4400c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory from initial separate dataframes\n",
    "\n",
    "del fulltextDF\n",
    "del resultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "081ebd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items from JSTOR: 2495\n",
      "Total number of items with at least one quotation detected: 518\n"
     ]
    }
   ],
   "source": [
    "# Drop items with no matches from results dataframe\n",
    "\n",
    "print(f\"Total number of items from JSTOR: {len(df)}\")\n",
    "df = df[df['numMatches']>=1]\n",
    "print(f\"Total number of items with at least one quotation detected: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b1626ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of quotations detected: 1758\n"
     ]
    }
   ],
   "source": [
    "# Expand the dataframe so each quotation becomes its own row\n",
    "\n",
    "df = df.explode(['Locations in A', 'Locations in B'])\n",
    "print(f\"Total number of quotations detected: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0fef0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace old indices with new indices\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96d22f",
   "metadata": {},
   "source": [
    "# OPTIONAL: filter results down to specific passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that can compare two intervals in the form of listed tuples, eg [x0, x1], [y0,y1]\n",
    "def overlaps(range1, range2):\n",
    "    try:\n",
    "        if len(range1) == 2 and len(range2) == 2:\n",
    "            return max(range1[0],range2[0]) < min(range1[1],range2[1])\n",
    "        else:\n",
    "            return False\n",
    "    except TypeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1af4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell specifies the start and end indices of the passage \n",
    "\n",
    "passageName = \"romanticSide\"\n",
    "quoteIndex = [4375, 4407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"doesOverlap\"] = df.apply(lambda x: overlaps(quoteIndex, x['Locations in A']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"doesOverlap\"]]\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a1447",
   "metadata": {},
   "source": [
    "# Generate context chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "37017d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify chunk size left and right\n",
    "num_characters_before_quote = 250\n",
    "num_characters_after_quote = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9d1d2870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now extracting context chunks for quotation 1758 of 1758\n"
     ]
    }
   ],
   "source": [
    "# Loop over each of the quotation start and end locations to produce\n",
    "# left and right context chunks of specified sizes\n",
    "\n",
    "allChunksLeft = []\n",
    "allChunksRight = []\n",
    "\n",
    "for item in range(len(df)):\n",
    "    article_URL = df['id'].iloc[item]\n",
    "    startandEndLocations = df['Locations in B'].iloc[item]\n",
    "    article_index = df[df['id'] == article_URL].index[0]\n",
    "    article_text = df['fullText'].iloc[article_index]\n",
    "\n",
    "    cleaned_article_text = Text(article_text, article_title)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"Now extracting context chunks for quotation {item + 1} of {len(df)}\")\n",
    "    \n",
    "    allChunksLeft.append((cleaned_article_text.text[startandEndLocations[0]-num_characters_before_quote:startandEndLocations[0]]))\n",
    "    allChunksRight.append((cleaned_article_text.text[startandEndLocations[1]:startandEndLocations[1]+num_characters_after_quote]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "151671c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLeft = pd.DataFrame(allChunksLeft, columns=['contextChunksLeft'])\n",
    "dfRight = pd.DataFrame(allChunksRight, columns=['contextChunksRight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b129d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Margaret Harris \"THE FRATERNITY OF OLD LAMPS\":...\n",
       "1       Margaret Harris \"THE FRATERNITY OF OLD LAMPS\":...\n",
       "2       Margaret Harris \"THE FRATERNITY OF OLD LAMPS\":...\n",
       "3       Margaret Harris \"THE FRATERNITY OF OLD LAMPS\":...\n",
       "4       [Authority and Invention in the Fiction of Bes...\n",
       "                              ...                        \n",
       "1753    ['DIE MORAL VON DER GESCHICHT': ART AND ARTIFI...\n",
       "1754    The Modernist Inkblot The Modernist Inkblot Em...\n",
       "1755    The Modernist Inkblot The Modernist Inkblot Em...\n",
       "1756    The Modernist Inkblot The Modernist Inkblot Em...\n",
       "1757    [INDIVIDUAL AUTHORS PETER ABRAHAMS C Chiwengo,...\n",
       "Name: fullText, Length: 1758, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge left and right context chunks into main dataframe\n",
    "df = pd.merge(df, dfLeft, left_index=True, right_index=True)\n",
    "df = pd.merge(dfTest, dfRight, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "372a0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop full text column\n",
    "df = df.drop(\"fullText\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "17fce97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSONL file\n",
    "df.to_json(path_or_buf=f\"{resultsDir}/{projectName}_results{hyperparSuffix}_contextChunks.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748f10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c31dc192",
   "metadata": {},
   "source": [
    "# Generate word frequency list for all context chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d7055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
