{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47c3c3a",
   "metadata": {},
   "source": [
    "# Getting \"context chunks\"\n",
    "\n",
    "This notebook serves to generate data on the immediate contexts before and after every quotation detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503f1ef",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b9f8a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from text_matcher.matcher import Text, Matcher\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "75fc130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION: copy path to results JSONL file here (filename should end \"_results_[hyperparameters].jsonl\")\n",
    "\n",
    "startData = \"/Users/milan/Library/CloudStorage/GoogleDrive-mtt2126@columbia.edu/My Drive/iAnnotate/MIT/Quotable Content/Data/Woolf/1925_Dalloway/Results/Woolf_1925_Dalloway_results_t2-c3-n2-m3-nostops.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9339de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author surname: Woolf\n",
      "Publication year: 1925\n",
      "Text title: Dalloway\n",
      "Hyperparameters suffix: _t2-c3-n2-m3-nostops\n",
      "Data directory:/Users/milan/Library/CloudStorage/GoogleDrive-mtt2126@columbia.edu/My Drive/iAnnotate/MIT/Quotable Content/Data\n"
     ]
    }
   ],
   "source": [
    "# Infer naming variables from path\n",
    "\n",
    "textTitle = startData.rsplit(\"_\", 4)[-3]\n",
    "publicationYear = startData.rsplit(\"_\", 4)[-4]\n",
    "authorSurname = startData.rsplit(\"_\", 4)[-5]\n",
    "authorSurname = authorSurname.rsplit(\"/\", 1)[-1]\n",
    "hyperparSuffix = startData.rsplit(\"_\", 4)[-1]\n",
    "hyperparSuffix = f\"_{hyperparSuffix[:-6]}\"\n",
    "dataDir = startData.rsplit(\"/\", 4)[0]\n",
    "\n",
    "print(f\"Author surname: {authorSurname}\\nPublication year: {publicationYear}\\nText title: {textTitle}\\nHyperparameters suffix: {hyperparSuffix}\\nData directory:{dataDir}\")\n",
    "\n",
    "projectName = f\"{authorSurname}_{publicationYear}_{textTitle}\"\n",
    "sourceDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/SourceText\"\n",
    "corpusDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/TargetCorpus\"\n",
    "resultsDir = f\"{dataDir}/{authorSurname}/{publicationYear}_{textTitle}/Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27267da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source text\n",
    "\n",
    "with open(f\"{sourceDir}/{projectName}_plaintext.txt\") as f: \n",
    "    rawText = f.read()\n",
    "\n",
    "mm = Text(rawText, 'Middlemarch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738d1f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2495 full-text items\n"
     ]
    }
   ],
   "source": [
    "# Load in the JSONL file with the full text of JSTOR articles\n",
    "\n",
    "corpusDF = pd.read_json(f\"{corpusDir}/{projectName}_fulltext.jsonl\", lines=True)\n",
    "print(f\"Loaded {len(corpusDF)} full-text items\")\n",
    "\n",
    "# Create new dataframe with just full text and id\n",
    "fulltextDF = corpusDF[[\"fullText\",\"id\"]]\n",
    "del corpusDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d826f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2495 results from text-matcher\n"
     ]
    }
   ],
   "source": [
    "# Load in the JSONL file with the results of text matcher\n",
    "\n",
    "resultsDF = pd.read_json(f\"{startData}\", lines=True)\n",
    "print(f\"Loaded {len(resultsDF)} results from text-matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0826a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(fulltextDF, resultsDF, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4400c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory from initial separate dataframes\n",
    "\n",
    "del fulltextDF\n",
    "del resultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081ebd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items from JSTOR: 2495\n",
      "Total number of items with at least one quotation detected: 518\n"
     ]
    }
   ],
   "source": [
    "# Drop items with no matches from results dataframe\n",
    "\n",
    "print(f\"Total number of items from JSTOR: {len(df)}\")\n",
    "df = df[df['numMatches']>=1]\n",
    "print(f\"Total number of items with at least one quotation detected: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1626ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of quotations detected: 1758\n"
     ]
    }
   ],
   "source": [
    "# Expand the dataframe so each quotation becomes its own row\n",
    "\n",
    "df = df.explode(['Locations in A', 'Locations in B'])\n",
    "print(f\"Total number of quotations detected: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fef0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace old indices with new indices\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a1447",
   "metadata": {},
   "source": [
    "# Generate context chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37017d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify chunk size left and right\n",
    "num_characters_before_quote = 250\n",
    "num_characters_after_quote = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1d2870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now extracting context chunks for quotation 1758 of 1758\n"
     ]
    }
   ],
   "source": [
    "# Loop over each of the quotation start and end locations to produce\n",
    "# left and right context chunks of specified sizes\n",
    "\n",
    "allChunksLeft = []\n",
    "allChunksRight = []\n",
    "allQuotedPassagesinB = []\n",
    "\n",
    "for item in range(len(df)):\n",
    "    article_URL = df['id'].iloc[item]\n",
    "    article_title = df['title'].iloc[item]\n",
    "    startandEndLocations = df['Locations in B'].iloc[item]\n",
    "    article_index = df[df['id'] == article_URL].index[0]\n",
    "    article_text = df['fullText'].iloc[article_index]\n",
    "\n",
    "    cleaned_article_text = Text(article_text, article_title)\n",
    "\n",
    "    clear_output()\n",
    "    print(f\"Now extracting context chunks for quotation {item + 1} of {len(df)}\")\n",
    "    \n",
    "    # Append the specified-size chunk left to complete list of left chunks\n",
    "    allChunksLeft.append((cleaned_article_text.text[startandEndLocations[0]-num_characters_before_quote:startandEndLocations[0]]))\n",
    "    # Append the specified-size chunk right to complete list of right chunks\n",
    "    allChunksRight.append((cleaned_article_text.text[startandEndLocations[1]:startandEndLocations[1]+num_characters_after_quote]))\n",
    "    # Append the quotation as it appears in the item to complete list of quoted passages\n",
    "    allQuotedPassagesinB.append((cleaned_article_text.text[startandEndLocations[0]:startandEndLocations[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "151671c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists into pandas dataframes\n",
    "dfLeft = pd.DataFrame(allChunksLeft, columns=['contextChunksLeft'])\n",
    "dfRight = pd.DataFrame(allChunksRight, columns=['contextChunksRight'])\n",
    "dfQuotesB = pd.DataFrame(allQuotedPassagesinB, columns=['quotedPassagesinB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b129d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge left and right context chunks and quoted passages into main dataframe\n",
    "df = pd.merge(df, dfLeft, left_index=True, right_index=True)\n",
    "df = pd.merge(df, dfRight, left_index=True, right_index=True)\n",
    "df = pd.merge(df, dfQuotesB, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372a0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop full text column\n",
    "df = df.drop(\"fullText\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17fce97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSONL file\n",
    "df.to_json(path_or_buf=f\"{resultsDir}/{projectName}_results{hyperparSuffix}_contextChunks.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c856f",
   "metadata": {},
   "source": [
    "# Output entire left/right contexts and quoted passages as text files (eg for word cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d748f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all left/right contexts as single text file\n",
    "\n",
    "output_file = open(f'{resultsDir}/{projectName}-allQuotationContexts.txt', mode='w', encoding='utf-8')\n",
    "\n",
    "for chunk in allChunksLeft:\n",
    "    output_file.write(chunk)\n",
    "    output_file.write('\\n')\n",
    "\n",
    "for chunk in allChunksRight:\n",
    "    output_file.write(chunk)\n",
    "    output_file.write('\\n')\n",
    "    \n",
    "output_file.close()\n",
    "\n",
    "# Output all quoted passages as single text file\n",
    "\n",
    "output_file = open(f'{resultsDir}/{projectName}-allQuotedPassagesinB.txt', mode='w', encoding='utf-8')\n",
    "for passage in allQuotedPassagesinB:\n",
    "    output_file.write(passage)\n",
    "    output_file.write('\\n')\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800ea87",
   "metadata": {},
   "source": [
    "# OPTIONAL: reimport JSONL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0f6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(f\"{resultsDir}/{projectName}_results{hyperparSuffix}_contextChunks.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62697ac4",
   "metadata": {},
   "source": [
    "\n",
    "# Calculate percentage change for keywords over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3743bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge left Chunk and right Chunk for each subset\n",
    "df[\"fullContextChunks\"] = df[\"contextChunksLeft\"] + \" \" + df[\"contextChunksRight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ce7c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rther comparison which illumin what meredith i...\n",
       "1    h a littl squeak of the hinges\" (p. 5), and th...\n",
       "2     dalloway from an acquaint pass by, which prov...\n",
       "3    he air. (p. 6) the leaden circl are to provid ...\n",
       "4    e and make it possibl for the reader to map th...\n",
       "Name: stemmedChunks, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stem all text\n",
    "\n",
    "import nltk\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "df['stemmedChunks'] = df.fullContextChunks.map(lambda x: ' '.join([stemmer.stem(y) for y in x.split(' ')]))\n",
    "df.stemmedChunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b55a8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify year at which the second period should start\n",
    "\n",
    "transitionPoint = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e94fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in first period up to (but excluding) 2010: 1356\n",
      "Items in second period starting from (and including) 2010: 402\n"
     ]
    }
   ],
   "source": [
    "# Create lists to contain text chunks\n",
    "\n",
    "firstPeriodChunks = []\n",
    "secondPeriodChunks = []\n",
    "\n",
    "# Append stemmed chunks to respective lists\n",
    "\n",
    "for item in range(len(df)):\n",
    "    currentChunk = df['stemmedChunks'].iloc[item]\n",
    "    if df['Year'].iloc[item] < transitionPoint:\n",
    "        firstPeriodChunks.append(currentChunk)\n",
    "    if df['Year'].iloc[item] >= transitionPoint:\n",
    "        secondPeriodChunks.append(currentChunk)\n",
    "        \n",
    "print(f\"Items in first period up to (but excluding) {transitionPoint}: {len(firstPeriodChunks)}\")\n",
    "print(f\"Items in second period starting from (and including) {transitionPoint}: {len(secondPeriodChunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2adf6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists into strings\n",
    "\n",
    "firstPeriodString = ' '.join(firstPeriodChunks)\n",
    "secondPeriodString = ' '.join(secondPeriodChunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f2ef47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "firstPeriodTokens = tokenizer.tokenize(firstPeriodString)\n",
    "secondPeriodTokens = tokenizer.tokenize(secondPeriodString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "54b2ed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in first period:  228723\n",
      "Total tokens in second period:  66704\n"
     ]
    }
   ],
   "source": [
    "print(\"Total tokens in first period: \" , len(firstPeriodTokens))\n",
    "print(\"Total tokens in second period: \" , len(secondPeriodTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ccdfb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tally up unique tokens\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "firstPeriodTallies = Counter()\n",
    "for word in firstPeriodTokens:\n",
    "    firstPeriodTallies[word] += 1\n",
    "\n",
    "secondPeriodTallies = Counter()\n",
    "for word in secondPeriodTokens:\n",
    "    secondPeriodTallies[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b173d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort tallies and reduce to top n tokens\n",
    "\n",
    "firstPeriodTallies = firstPeriodTallies.most_common()[0:500]\n",
    "secondPeriodTallies = secondPeriodTallies.most_common()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4bc14429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>FirstPeriodRawFreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>14077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>8388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>5065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>4902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>character</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>art</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>role</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>people</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  FirstPeriodRawFreq\n",
       "0          the               14077\n",
       "1           of                8388\n",
       "2          and                5957\n",
       "3           to                5065\n",
       "4            a                4902\n",
       "..         ...                 ...\n",
       "495  character                  56\n",
       "496        art                  56\n",
       "497       role                  56\n",
       "498     people                  56\n",
       "499         12                  56\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for top first period keyword  tallies\n",
    "\n",
    "firstTalliesDF = pd.DataFrame(firstPeriodTallies, columns =['Token', 'FirstPeriodRawFreq'])\n",
    "firstTalliesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc7e20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for top first period keyword  tallies\n",
    "\n",
    "secondTalliesDF = pd.DataFrame(secondPeriodTallies, columns =['Token', 'SecondPeriodRawFreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "376b5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentChangeDF = pd.merge(firstTalliesDF, secondTalliesDF, on=\"Token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "10c0b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide raw frequencies by total number of tokens for each period\n",
    "\n",
    "percentChangeDF[\"FirstPeriodRelativeFreq\"] = percentChangeDF[\"FirstPeriodRawFreq\"] / len(firstPeriodTokens)\n",
    "percentChangeDF[\"SecondPeriodRelativeFreq\"] = percentChangeDF[\"SecondPeriodRawFreq\"] / len(secondPeriodTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "25f11234",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentChangeDF[\"PercentageChange\"] = (percentChangeDF[\"SecondPeriodRelativeFreq\"] - percentChangeDF[\"FirstPeriodRelativeFreq\"]) / percentChangeDF[\"FirstPeriodRelativeFreq\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7035708",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3d17bf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>FirstPeriodRawFreq</th>\n",
       "      <th>SecondPeriodRawFreq</th>\n",
       "      <th>FirstPeriodRelativeFreq</th>\n",
       "      <th>SecondPeriodRelativeFreq</th>\n",
       "      <th>PercentageChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>space</td>\n",
       "      <td>63</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>166.694151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>tree</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>146.882586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>connect</td>\n",
       "      <td>102</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>145.403442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>car</td>\n",
       "      <td>77</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>136.016902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>move</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>127.110604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>hous</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>126.751479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>modern</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>121.625627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>present</td>\n",
       "      <td>139</td>\n",
       "      <td>89</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>119.549861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>kind</td>\n",
       "      <td>79</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>99.658913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>dure</td>\n",
       "      <td>59</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>91.787319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>scene</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>89.493213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>beauti</td>\n",
       "      <td>67</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>89.358534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>actual</td>\n",
       "      <td>69</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>88.839337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>md</td>\n",
       "      <td>327</td>\n",
       "      <td>173</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>81.407948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>rezia</td>\n",
       "      <td>157</td>\n",
       "      <td>82</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>79.090340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>relat</td>\n",
       "      <td>74</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>76.079922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>doe</td>\n",
       "      <td>161</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>72.511124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>between</td>\n",
       "      <td>247</td>\n",
       "      <td>124</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>72.140354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>literatur</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>71.446240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>might</td>\n",
       "      <td>154</td>\n",
       "      <td>76</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>69.219666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  FirstPeriodRawFreq  SecondPeriodRawFreq  \\\n",
       "377      space                  63                   49   \n",
       "330       tree                  75                   54   \n",
       "254    connect                 102                   73   \n",
       "325        car                  77                   53   \n",
       "324       move                  77                   51   \n",
       "383       hous                  62                   41   \n",
       "307     modern                  82                   53   \n",
       "193    present                 139                   89   \n",
       "318       kind                  79                   46   \n",
       "391       dure                  59                   33   \n",
       "230      scene                 114                   63   \n",
       "358     beauti                  67                   37   \n",
       "348     actual                  69                   38   \n",
       "72          md                 327                  173   \n",
       "171      rezia                 157                   82   \n",
       "333      relat                  74                   38   \n",
       "162        doe                 161                   81   \n",
       "102    between                 247                  124   \n",
       "381  literatur                  62                   31   \n",
       "173      might                 154                   76   \n",
       "\n",
       "     FirstPeriodRelativeFreq  SecondPeriodRelativeFreq  PercentageChange  \n",
       "377                 0.000275                  0.000735        166.694151  \n",
       "330                 0.000328                  0.000810        146.882586  \n",
       "254                 0.000446                  0.001094        145.403442  \n",
       "325                 0.000337                  0.000795        136.016902  \n",
       "324                 0.000337                  0.000765        127.110604  \n",
       "383                 0.000271                  0.000615        126.751479  \n",
       "307                 0.000359                  0.000795        121.625627  \n",
       "193                 0.000608                  0.001334        119.549861  \n",
       "318                 0.000345                  0.000690         99.658913  \n",
       "391                 0.000258                  0.000495         91.787319  \n",
       "230                 0.000498                  0.000944         89.493213  \n",
       "358                 0.000293                  0.000555         89.358534  \n",
       "348                 0.000302                  0.000570         88.839337  \n",
       "72                  0.001430                  0.002594         81.407948  \n",
       "171                 0.000686                  0.001229         79.090340  \n",
       "333                 0.000324                  0.000570         76.079922  \n",
       "162                 0.000704                  0.001214         72.511124  \n",
       "102                 0.001080                  0.001859         72.140354  \n",
       "381                 0.000271                  0.000465         71.446240  \n",
       "173                 0.000673                  0.001139         69.219666  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output 20 biggest increases\n",
    "\n",
    "percentChangeDF.sort_values(by=[\"PercentageChange\"], ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "966b5d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>FirstPeriodRawFreq</th>\n",
       "      <th>SecondPeriodRawFreq</th>\n",
       "      <th>FirstPeriodRelativeFreq</th>\n",
       "      <th>SecondPeriodRelativeFreq</th>\n",
       "      <th>PercentageChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>p</td>\n",
       "      <td>912</td>\n",
       "      <td>41</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-84.584878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>walsh</td>\n",
       "      <td>229</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>-62.566323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>did</td>\n",
       "      <td>230</td>\n",
       "      <td>26</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>-61.238241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>hand</td>\n",
       "      <td>169</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-59.421008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kilman</td>\n",
       "      <td>325</td>\n",
       "      <td>43</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>-54.632687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>bruton</td>\n",
       "      <td>143</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-52.043010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>sir</td>\n",
       "      <td>157</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-51.951372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>william</td>\n",
       "      <td>162</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-51.317734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>some</td>\n",
       "      <td>328</td>\n",
       "      <td>49</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>-48.775209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>power</td>\n",
       "      <td>191</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-47.937791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>say</td>\n",
       "      <td>201</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-47.116085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>death</td>\n",
       "      <td>445</td>\n",
       "      <td>70</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>-46.061857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>miss</td>\n",
       "      <td>262</td>\n",
       "      <td>42</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-45.032503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>too</td>\n",
       "      <td>192</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-44.637152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>much</td>\n",
       "      <td>127</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-43.301243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>felt</td>\n",
       "      <td>227</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-42.599497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>herself</td>\n",
       "      <td>401</td>\n",
       "      <td>68</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>-41.853644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>imag</td>\n",
       "      <td>169</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-41.160462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>parti</td>\n",
       "      <td>203</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-40.880607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>party</td>\n",
       "      <td>195</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-38.455196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Token  FirstPeriodRawFreq  SecondPeriodRawFreq  \\\n",
       "29         p                 912                   41   \n",
       "116    walsh                 229                   25   \n",
       "115      did                 230                   26   \n",
       "157     hand                 169                   20   \n",
       "76    kilman                 325                   43   \n",
       "186   bruton                 143                   20   \n",
       "170      sir                 157                   22   \n",
       "160  william                 162                   23   \n",
       "71      some                 328                   49   \n",
       "140    power                 191                   29   \n",
       "134      say                 201                   31   \n",
       "55     death                 445                   70   \n",
       "93      miss                 262                   42   \n",
       "139      too                 192                   31   \n",
       "208     much                 127                   21   \n",
       "118     felt                 227                   38   \n",
       "60   herself                 401                   68   \n",
       "158     imag                 169                   29   \n",
       "132    parti                 203                   35   \n",
       "136    party                 195                   35   \n",
       "\n",
       "     FirstPeriodRelativeFreq  SecondPeriodRelativeFreq  PercentageChange  \n",
       "29                  0.003987                  0.000615        -84.584878  \n",
       "116                 0.001001                  0.000375        -62.566323  \n",
       "115                 0.001006                  0.000390        -61.238241  \n",
       "157                 0.000739                  0.000300        -59.421008  \n",
       "76                  0.001421                  0.000645        -54.632687  \n",
       "186                 0.000625                  0.000300        -52.043010  \n",
       "170                 0.000686                  0.000330        -51.951372  \n",
       "160                 0.000708                  0.000345        -51.317734  \n",
       "71                  0.001434                  0.000735        -48.775209  \n",
       "140                 0.000835                  0.000435        -47.937791  \n",
       "134                 0.000879                  0.000465        -47.116085  \n",
       "55                  0.001946                  0.001049        -46.061857  \n",
       "93                  0.001145                  0.000630        -45.032503  \n",
       "139                 0.000839                  0.000465        -44.637152  \n",
       "208                 0.000555                  0.000315        -43.301243  \n",
       "118                 0.000992                  0.000570        -42.599497  \n",
       "60                  0.001753                  0.001019        -41.853644  \n",
       "158                 0.000739                  0.000435        -41.160462  \n",
       "132                 0.000888                  0.000525        -40.880607  \n",
       "136                 0.000853                  0.000525        -38.455196  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output 20 biggest decreases\n",
    "\n",
    "percentChangeDF.sort_values(by=[\"PercentageChange\"])[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb584e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ab097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d1776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1a456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9105125",
   "metadata": {},
   "source": [
    "# TBD: run tf-idf on filtered version of df compared to rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: re-import JSONL file as pandas dataframe\n",
    "df = pd.read_csv('my_data_with_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c04d2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fullContextChunks\"] = df[\"contextChunksLeft\"] + \" \" + df[\"contextChunksRight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91ac3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6ea7172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rther comparison which illumin what meredith i...\n",
       "1    h a littl squeak of the hinges\" (p. 5), and th...\n",
       "2     dalloway from an acquaint pass by, which prov...\n",
       "3    he air. (p. 6) the leaden circl are to provid ...\n",
       "4    e and make it possibl for the reader to map th...\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "df['stemmed'] = df.fullContextChunks.map(lambda x: ' '.join([stemmer.stem(y) for y in x.split(' ')]))\n",
    "df.stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b88c7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10a61bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 2), stop_words='english')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words='english', min_df=2, max_df=0.5, ngram_range=(1,2))\n",
    "cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abd61388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comparison', 6963),\n",
       " ('illumin', 15414),\n",
       " ('meredith', 19899),\n",
       " ('provid', 24771),\n",
       " ('begin', 4077),\n",
       " ('mrs', 20710),\n",
       " ('dalloway', 8154),\n",
       " ('virginia', 33543),\n",
       " ('woolf', 34783),\n",
       " ('open', 22031),\n",
       " ('novel', 21433),\n",
       " ('charact', 5663),\n",
       " ('foot', 12951),\n",
       " ('london', 18531),\n",
       " ('appar', 2855),\n",
       " ('arbitrari', 2989),\n",
       " ('sentenc', 27854),\n",
       " ('gradual', 13879),\n",
       " ('explained', 11726),\n",
       " ('fresh', 13216)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate all the n-grams found in all documents\n",
    "from itertools import islice\n",
    "cvec.fit(df.stemmed)\n",
    "list(islice(cvec.vocabulary_.items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a07ab4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35472"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many total n-grams we have\n",
    "len(cvec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bd11921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (1758, 35472)\n",
      "nonzero count: 202159\n",
      "sparsity: 0.32%\n"
     ]
    }
   ],
   "source": [
    "cvec_counts = cvec.transform(df.stemmed)\n",
    "print('sparse matrix shape:', cvec_counts.shape)\n",
    "print('nonzero count:', cvec_counts.nnz)\n",
    "print('sparsity: %.2f%%' % (100.0 * cvec_counts.nnz / (cvec_counts.shape[0] * cvec_counts.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac869dea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m occ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(cvec_counts\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 2\u001b[0m counts_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterm\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names\u001b[49m(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccurrences\u001b[39m\u001b[38;5;124m'\u001b[39m: occ})\n\u001b[1;32m      3\u001b[0m counts_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moccurrences\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "occ = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()\n",
    "counts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'occurrences': occ})\n",
    "counts_df.sort_values(by='occurrences', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d3f9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7c613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57009c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a504e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad3eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd96d22f",
   "metadata": {},
   "source": [
    "# OPTIONAL: filter results down to specific passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that can compare two intervals in the form of listed tuples, eg [x0, x1], [y0,y1]\n",
    "def overlaps(range1, range2):\n",
    "    try:\n",
    "        if len(range1) == 2 and len(range2) == 2:\n",
    "            return max(range1[0],range2[0]) < min(range1[1],range2[1])\n",
    "        else:\n",
    "            return False\n",
    "    except TypeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1af4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell specifies the start and end indices of the passage \n",
    "\n",
    "passageName = \"romanticSide\"\n",
    "quoteIndex = [4375, 4407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"doesOverlap\"] = df.apply(lambda x: overlaps(quoteIndex, x['Locations in A']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"doesOverlap\"]]\n",
    "df = df.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
